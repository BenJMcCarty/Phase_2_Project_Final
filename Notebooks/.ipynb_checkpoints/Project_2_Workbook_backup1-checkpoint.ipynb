{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2 Workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For the first part of the project, you will try to determine what affects housing prices using **exploratory data analysis, hypothesis tests, and linear regression**. \n",
    "\n",
    "\n",
    "* The goal of this analysis is to be able to come away with valuable insights regarding home prices. \n",
    "\n",
    "\n",
    "* Imagine a real estate agent comes to you and asks for information about the housing market in Kings County.\n",
    " * What would your analysis tell them that would be helpful to them as they help clients buy and sell houses?\n",
    "\n",
    "\n",
    "* *Imagine homeowners from Kings County want to increase the resale value of their home.*\n",
    "     * They are willing to spend some money on renovations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Exploratory Data Analysis (EDA):** You must create **at least 4 data visualizations** that help to explain the data. These visualizations should help someone unfamiliar with the data understand the target variable and the features that help explain that target variable.\n",
    "\n",
    "- **Feature Engineering:** You must create **at least 3 new features** that you think will are related to the price of a house. In the notebook you you need to explain the features you engineer and your thought process behind why you created them.  \n",
    "\n",
    "- **Statistical Tests:** Your notebook must show **at least 3 statistical tests** that you preformed on your data set. Think of these as being part of your EDA process; for example, if you think houses with a view cost more than those without a view, then perform a two-sample T-test. These willpreliminary evidence that a feature will be important in your model.  \n",
    "\n",
    "- **Linear Regression Model:** One of the benefits of a linear regression model is that you can **interpret the coefficients** of the model **to derive insights**. For example, which feature has the biggest impact on the price of the house? Was there a feature that you thought would be significant but was not once other features were considered?  Models for inference are typically simpler so they are more straight forward to interpret, so you probably won't include all of your features in this model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T20:49:25.827176Z",
     "start_time": "2021-05-29T20:49:25.815174Z"
    }
   },
   "source": [
    "## PROCESS CHECKLIST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T20:49:47.494041Z",
     "start_time": "2021-05-29T20:49:47.476056Z"
    }
   },
   "source": [
    "> Keep in mind that it is normal to jump between the OSEMN phases and some of them will blend together, like SCRUB and EXPLORE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **[OBTAIN](#OBTAIN)**\n",
    "    - Import data, inspect, check for datatypes to convert and null values\n",
    "    - Display header and info.\n",
    "    - Drop any unneeded columns, if known (`df.drop(['col1','col2'],axis=1,inplace=True`)\n",
    "    <br><br>\n",
    "\n",
    "\n",
    "2. **[SCRUB](#SCRUB)**\n",
    "    - Recast data types, identify outliers, check for multicollinearity, normalize data**\n",
    "    - Check and cast data types\n",
    "        - [ ] Check for #'s that are store as objects (`df.info()`,`df.describe()`)\n",
    "            - when converting to #'s, look for odd values (like many 0's), or strings that can't be converted.\n",
    "            - Decide how to deal weird/null values (`df.unique()`, `df.isna().sum()`)\n",
    "            - `df.fillna(subset=['col_with_nulls'],'fill_value')`, `df.replace()`\n",
    "        - [ ] Check for categorical variables stored as integers.\n",
    "            - May be easier to tell when you make a scatter plotm or `pd.plotting.scatter_matrix()`\n",
    "            \n",
    "    - [ ] Check for missing values` (df.isna().sum())`\n",
    "        - Can drop rows or colums\n",
    "        - For missing numeric data with median or bin/convert to categorical\n",
    "        - For missing categorical data: make NaN own category OR replace with most common category\n",
    "    - [ ] Check for multicollinearity\n",
    "        - Use seaborn to make correlation matrix plot \n",
    "        - Good rule of thumb is anything over 0.75 corr is high, remove the variable that has the most correl with the largest # of variables\n",
    "    - [ ] Normalize data (may want to do after some exploring)\n",
    "        - Most popular is Z-scoring (but won't fix skew) \n",
    "        - Can log-transform to fix skewed data\n",
    "    \n",
    "    \n",
    "3. **[EXPLORE](#EXPLORE)**\n",
    "    - [ ] Check distributions, outliers, etc**\n",
    "    - [ ] Check scales, ranges (df.describe())\n",
    "    - [ ] Check histograms to get an idea of distributions (df.hist()) and data transformations to perform.\n",
    "        - Can also do kernel density estimates\n",
    "    - [ ] Use scatter plots to check for linearity and possible categorical variables (`df.plot(\"x\",\"y\")`)\n",
    "        - categoricals will look like vertical lines\n",
    "    - [ ] Use `pd.plotting.scatter_matrix(df)` to visualize possible relationships\n",
    "    - [ ] Check for linearity.\n",
    "   \n",
    "   \n",
    "4. **[MODEL](#MODEL)**\n",
    "\n",
    "    - **Fit an initial model:** \n",
    "        - Run an initial model and get results\n",
    "\n",
    "    - **Holdout validation / Train/test split**\n",
    "        - use sklearn `train_test_split`\n",
    "    \n",
    "    \n",
    "5. **[iNTERPRET](#iNTERPRET)**\n",
    "    - **Assessing the model:**\n",
    "        - Assess parameters (slope,intercept)\n",
    "        - Check if the model explains the variation in the data (RMSE, F, R_square)\n",
    "        - *Are the coeffs, slopes, intercepts in appropriate units?*\n",
    "        - *Whats the impact of collinearity? Can we ignore?*\n",
    "        <br><br>\n",
    "    - **Revise the fitted model**\n",
    "        - Multicollinearity is big issue for lin regression and cannot fully remove it\n",
    "        - Use the predictive ability of model to test it (like R2 and RMSE)\n",
    "        - Check for missed non-linearity\n",
    "        \n",
    "       \n",
    "6. **Interpret final model and draw >=3 conclusions and recommendations from dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T20:54:16.007954Z",
     "start_time": "2021-05-27T20:54:15.982975Z"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:01.453337Z",
     "start_time": "2021-06-03T00:01:59.185342Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Data Handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import json\n",
    "import plotly.express as px\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sms\n",
    "\n",
    "# Settings\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-talk')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The following functions enable the user to filter a Pandas series and return a boolean index to use for filtering out the outliers.\n",
    ">\n",
    "> In order to use the functions effectively, the results must be saved to a new variable. Then the user can perform further filtering by using the new variable to slice the dataframe to be filtered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ƒ: `find_outliers_z`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:01.468371Z",
     "start_time": "2021-06-03T00:02:01.455338Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check using z-score - sensitive to outliers\n",
    "\n",
    "def find_outliers_z(data):\n",
    "    \"\"\"Detects outliers using the Z-score>3 cutoff.\n",
    "    Returns a boolean Series where True=outlier\n",
    "    \n",
    "    Source: https://github.com/jirvingphd/dsc-phase-2-project/blob/main/functions_SG.py\n",
    "    \"\"\"\n",
    "    \n",
    "    zFP = np.abs(stats.zscore(data))\n",
    "    zFP = pd.Series(zFP, index=data.index)\n",
    "    idx_outliers = zFP > 3\n",
    "    return idx_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ƒ: `find_outliers_IQR`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:01.499340Z",
     "start_time": "2021-06-03T00:02:01.471340Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check using IQR - less sensitive to outliers\n",
    "\n",
    "def find_outliers_IQR(data):\n",
    "    \"\"\"\n",
    "    * Takes a series sliced from a dataframe\n",
    "    * Detects outliers using the 1.5*IQR thresholds.\n",
    "    * Returns a boolean Series where True=outlier\n",
    "\n",
    "    Source: https://github.com/jirvingphd/dsc-phase-2-project/blob/main/functions_SG.py\n",
    "    \"\"\"\n",
    "    \n",
    "    res = data.describe()\n",
    "    q1 = res['25%']\n",
    "    q3 = res['75%']\n",
    "    thresh = 1.5*(q3-q1)\n",
    "    idx_outliers =(data < (q1-thresh)) | (data > (q3+thresh))\n",
    "    return idx_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:01.514339Z",
     "start_time": "2021-06-03T00:02:01.503345Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Testing Z-Score method\n",
    "\n",
    "# # Run function\n",
    "# idx_bdrm_out_z = find_outliers_z(df['bedrooms'])\n",
    "\n",
    "# # Save non-outliers as new variable \n",
    "# df_bdrm_clean_z = df[~idx_bdrm_out_z].copy()\n",
    "\n",
    "# # Print total number of outliers from data\n",
    "# print(f'There were {idx_bdrm_out.sum()} outliers.')\n",
    "\n",
    "# # Show final data\n",
    "# df_bdrm_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:01.530347Z",
     "start_time": "2021-06-03T00:02:01.516340Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Testing IQR method\n",
    "\n",
    "# # Run function\n",
    "# idx_bdrm_out_iqr = find_outliers_IQR(df['bedrooms'])\n",
    "\n",
    "# # Save non-outliers as new variable \n",
    "# df_bdrm_clean_iqr = df[~idx_bdrm_out_iqr].copy()\n",
    "\n",
    "# # Print total number of outliers from data\n",
    "# print(f'There were {idx_bdrm_out_iqr.sum()} outliers.')\n",
    "\n",
    "# # Show final data\n",
    "# df_bdrm_clean_iqr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new functions for cleaning and visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ƒ: `feature_vis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:01.623341Z",
     "start_time": "2021-06-03T00:02:01.533338Z"
    }
   },
   "outputs": [],
   "source": [
    "def feature_vis(data, x, y = 'price', discrete = False, kde = True):\n",
    "    '''-----\n",
    "    * Requires a DataFrame and a column name to process.\n",
    "    * Keyword arguments specify that the target variable will be \"price\"\n",
    "    for this case.\n",
    "    * For future use, redefine function without predetermined y-value, or \n",
    "    reassign.\n",
    "    \n",
    "    --\n",
    "    \n",
    "    * Args:\n",
    "        * Data: Pandas DataFrame; data source\n",
    "        * x: str; column index to specify data\n",
    "    \n",
    "    * Kwargs:\n",
    "        * y = \"price\"\n",
    "        * discrete = False\n",
    "        * kde = true\n",
    "        \n",
    "    -----'''\n",
    "    \n",
    "    ## Print the slice of the original DataFrame for easy viewing\n",
    "    \n",
    "    print(df[x].value_counts().sort_index())\n",
    "  \n",
    "    ## Create two plots via Seaborn: one scatter plot with regression line,\n",
    "    ## then a histogram of the data (with KDE if specified\n",
    "    \n",
    "    fig, axs = plt.subplots(ncols=2, figsize= (12,6))\n",
    "    \n",
    "    sns.regplot(data=data, x=x, y=y, ax=axs[0])\n",
    "    sns.histplot(data=data, x=x, discrete=discrete, kde=kde, ax=axs[1])\n",
    "    \n",
    "    fig.suptitle(f'{x.title()} vs. {y.title()}', fontsize=16)\n",
    "    plt.tight_layout();\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ƒ: `filter_outliers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:01.639341Z",
     "start_time": "2021-06-03T00:02:01.625337Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_outliers(data):\n",
    "    '''------\n",
    "    \n",
    "    * Removes outliers from data via \"find_outliers_IQR\" and saves filtered\n",
    "    values to the dataframe\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    * Arg:\n",
    "        * Data: slice of a dataframe for a specific column header\n",
    "    \n",
    "    ------\n",
    "    '''\n",
    "   \n",
    "    idx_out = find_outliers_IQR(data)\n",
    " \n",
    "    cleaned = df[~idx_out]\n",
    "\n",
    "    print(f'There were {idx_out.sum()} outliers.')\n",
    "    \n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ✨ ƒ: `remove_outliers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:01.655339Z",
     "start_time": "2021-06-03T00:02:01.642339Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_outliers(data, x):\n",
    "\n",
    "    idx_out = find_outliers_IQR(data[x])\n",
    " \n",
    "    df_clean = df[~idx_out].copy()\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ƒ: `show_cleaned_vis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:01.671393Z",
     "start_time": "2021-06-03T00:02:01.658339Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def show_cleaned_vis(data, x, y = 'price', discrete = False, kde = True):\n",
    "    '''-----\n",
    "    \n",
    "    * Combines functions to filter outliers and to create the feature \n",
    "        visualizations.\n",
    "    * Requres 'find_outliers_IQR' and 'feature_vis' to be defined.\n",
    "    * Returns filtered data and two visualizations - Seaborn regression plot\n",
    "        and histplot.\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    * Args:\n",
    "        * Data: Pandas DataFrame; data source\n",
    "        * x: str; column index to specify data\n",
    "    * Kwargs\n",
    "    \n",
    "    -----'''\n",
    "    \n",
    "    ### Filter outliers first\n",
    "    \n",
    "    idx_out = find_outliers_IQR(data[x])\n",
    " \n",
    "    df_cleaned = df[~idx_out].copy()\n",
    "\n",
    "    print(f'There were {idx_out.sum()} outliers.')\n",
    "    \n",
    "    ### Plot Data\n",
    "    \n",
    "    \n",
    "    df_cleaned[x].value_counts().sort_index()\n",
    "        \n",
    "    fig, axs = plt.subplots(ncols=2, figsize= (12,6))\n",
    "    \n",
    "    sns.regplot(data=df_cleaned, x=x, y=y, ax=axs[0])\n",
    "    sns.histplot(data=df_cleaned, x=x, discrete=discrete, kde=kde, ax=axs[1])\n",
    "    \n",
    "    fig.suptitle(f'{x.title()} vs. {y.title()}', fontsize=16)\n",
    "    plt.tight_layout();\n",
    "    \n",
    "    return #df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Function for T-Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ƒ: `ttest_review`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:01.687482Z",
     "start_time": "2021-06-03T00:02:01.673339Z"
    }
   },
   "outputs": [],
   "source": [
    "def ttest_review(sample_1, sample_2, alpha=.05):\n",
    "    '''------\n",
    "    * Runs a t-test on two samples; prints whether or not they are significant,\n",
    "    and returns p-value as a variable called \"p-value.\"\n",
    "    * Requires two data samples and an alpha value.\n",
    "    \n",
    "    ----\n",
    "    \n",
    "    * Args: two data samples for t-test\n",
    "    * Kwargs: alpha=.05\n",
    "    \n",
    "    -----\n",
    "    '''\n",
    "    \n",
    "    result = stats.ttest_ind(sample_1, sample_2)\n",
    "    crit_val, p_val = result\n",
    "    \n",
    "    ## Creating interpretation based on p-value results.\n",
    "\n",
    "    if p_value < .05:\n",
    "        print(f'The feature \"waterfront\" is statistically significant with a p-value of {p_val}.')\n",
    "\n",
    "    else:\n",
    "         print(f'The feature \"waterfront\" is not statistically significant with a p-value of {p_val}.')\n",
    "    \n",
    "    return p_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T20:54:28.453145Z",
     "start_time": "2021-05-27T20:54:28.440146Z"
    }
   },
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:04:03.088313Z",
     "start_time": "2021-06-03T00:04:03.035322Z"
    }
   },
   "outputs": [],
   "source": [
    "df= pd.read_csv('kc_house_data_train.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Fresh Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Overviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:01.779341Z",
     "start_time": "2021-06-03T00:02:01.736341Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:01.810351Z",
     "start_time": "2021-06-03T00:02:01.782340Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DF Columns to Convert**\n",
    "\n",
    "* 'date' obj -> datetime; may drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:01.825352Z",
     "start_time": "2021-06-03T00:02:01.813338Z"
    }
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> No null values to worry about. Next, I will inspect each column to explore features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:01.917349Z",
     "start_time": "2021-06-03T00:02:01.828339Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T17:18:18.910952Z",
     "start_time": "2021-05-29T17:18:18.894430Z"
    }
   },
   "source": [
    "## Exploring Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **The \"feature_vis\" function is designed to take a given feature as an argument, then return the raw values and two plots.** The first plot is a scatter plot with regression line, and the second plot is a histogram (with/out KDE plot overlaid if specified when running function).**\n",
    ">\n",
    "> **The benefit of this function** is that we are able to identify categorical vs. continuous variables and get an estimation of the relationship between the variable and our dependent variable, \"Price.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bedrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:03.460337Z",
     "start_time": "2021-06-03T00:02:01.919338Z"
    }
   },
   "outputs": [],
   "source": [
    "show_cleaned_vis(df,\"bedrooms\", discrete=True, kde = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:03.506340Z",
     "start_time": "2021-06-03T00:02:03.463338Z"
    }
   },
   "outputs": [],
   "source": [
    "remove_outliers(df, 'bedrooms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Observations**\n",
    "\n",
    ">* Odd: 0 or 33 bedrooms\n",
    ">* Box Plot tells us that the high outliers would include anything above 5 bedrooms.\n",
    ">  * We know that we want to include some of those, though.\n",
    ">* Somewhat linear relationship until about 6 bedrooms - initial best-fit line has stronger slope at max 5 bedrooms\n",
    "***\n",
    "**TO-DO**\n",
    "\n",
    ">* Identify and remove outliers\n",
    ">* Use Bedrooms as numerical\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bathrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:04.722340Z",
     "start_time": "2021-06-03T00:02:03.508337Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_cleaned_vis(df,\"bathrooms\", discrete=True, kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Observations**\n",
    "\n",
    ">* Some outliers may be throwing off the counts\n",
    ">* Somewhat linear relationship\n",
    ">* Zero bathrooms??\n",
    "\n",
    "***\n",
    "**TO-DO**\n",
    "\n",
    ">* Investigate outliers - 0/7+ bathrooms, higher prices\n",
    ">* Create box plot to get clearer idea of outliers\n",
    "*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sqft_living"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:06.092340Z",
     "start_time": "2021-06-03T00:02:04.724340Z"
    }
   },
   "outputs": [],
   "source": [
    "show_cleaned_vis(df,\"sqft_living\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Observations**\n",
    "\n",
    ">* Check outliers - throwing off graphs\n",
    ">* Positive correlation, seems linear\n",
    ">* Most seem to be about 2k sq. ft.\n",
    "\n",
    "***\n",
    "**TO-DO**\n",
    "\n",
    ">* Check outliers\n",
    ">* Use as continuous variable\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sqft_lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:06.108339Z",
     "start_time": "2021-06-03T00:02:06.095338Z"
    }
   },
   "outputs": [],
   "source": [
    "# show_cleaned_vis(df,\"sqft_lot\", kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Observations**\n",
    "\n",
    ">* **Significant** outliers throwing off the numbers considerably.\n",
    ">* May be normally distributed\n",
    "\n",
    "***\n",
    "\n",
    "**TO-DO**\n",
    "\n",
    ">* Correct outliers\n",
    ">* run .describe()\n",
    "\n",
    "* **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### floors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:06.124337Z",
     "start_time": "2021-06-03T00:02:06.112338Z"
    }
   },
   "outputs": [],
   "source": [
    "# show_cleaned_vis(df,\"floors\", kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Observations**\n",
    "\n",
    ">* Few outliers\n",
    ">* 1.5, 2.5 floors?\n",
    ">* Mostly 1 or 2\n",
    "\n",
    "***\n",
    "**TO-DO**\n",
    "\n",
    ">* Outliers\n",
    ">* Investigate .5 floors\n",
    " \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### waterfront"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:06.139338Z",
     "start_time": "2021-06-03T00:02:06.127339Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# show_cleaned_vis(df,\"waterfront\", discrete=True, kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Observations**\n",
    "\n",
    ">* Graphs are misleading\n",
    ">* Most properties are non-waterfront\n",
    ">* Looks like price increases with waterfront feature\n",
    "\n",
    "***\n",
    "**TO-DO**\n",
    "\n",
    ">* Change graphs\n",
    ">* Check the few outliers\n",
    ">* \n",
    " \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:06.155340Z",
     "start_time": "2021-06-03T00:02:06.150340Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# show_cleaned_vis(df,\"view\", discrete=True, kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Observations**\n",
    "\n",
    ">* Higher \"view\" rating, higher price\n",
    ">* Most have '0' view\n",
    ">* A few extreme outliers in pricing\n",
    "\n",
    "***\n",
    "**TO-DO**\n",
    "\n",
    ">* Check outliers \n",
    ">* Treat as categorical\n",
    ">* \n",
    " \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:07.386337Z",
     "start_time": "2021-06-03T00:02:06.160345Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_cleaned_vis(df,\"condition\", discrete=True, kde= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Observations**\n",
    "\n",
    ">* Largest number of homes sold were in condition 3\n",
    ">* Very few sold in 1s, 2s\n",
    ">* Price outliers in 4.0 area, some slight outliers in 2 and 3\n",
    "\n",
    "***\n",
    "**TO-DO**\n",
    "\n",
    ">* Treat as categorical\n",
    ">* Investigate outliers\n",
    ">*\n",
    " \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:07.401337Z",
     "start_time": "2021-06-03T00:02:07.388338Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# show_cleaned_vis(df,\"grade\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "* Clear linear trend - as grade increases, so does price\n",
    "\n",
    "\n",
    "* Largest range of grades is 6-9\n",
    "\n",
    "\n",
    "* Grade 13 - very few houses sold; worth investigating\n",
    "\n",
    "\n",
    "**TO-DO**\n",
    "\n",
    "* Investigate grade 13 houses\n",
    "\n",
    "\n",
    "* Outliers: >= 4, one at 11\n",
    "\n",
    "\n",
    "* Continuous variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sqft_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:07.417338Z",
     "start_time": "2021-06-03T00:02:07.403338Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# show_cleaned_vis(df,\"sqft_above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "* Outliers impacting accuracy of linear regression\n",
    "\n",
    "\n",
    "* Dist. skewed left\n",
    "\n",
    "\n",
    "* \n",
    "\n",
    "\n",
    "**TO-DO**\n",
    "\n",
    "* Outliers\n",
    "\n",
    "\n",
    "* Continuous\n",
    "\n",
    "\n",
    "*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sqft_basement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:07.432338Z",
     "start_time": "2021-06-03T00:02:07.419339Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# show_cleaned_vis(df,\"sqft_basement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "* Lots of 0 SQFT basements - no basement at all on property\n",
    "\n",
    "\n",
    "* scattered outliers; poor regression due to outliers and 0s\n",
    "\n",
    "\n",
    "* some extreme outliers\n",
    "\n",
    "\n",
    "**TO-DO**\n",
    "\n",
    "* investigate high outliers for basement sizes\n",
    "\n",
    "\n",
    "* for modeling, ignore 0 SQFT\n",
    "\n",
    "\n",
    "*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### yr_built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:07.447338Z",
     "start_time": "2021-06-03T00:02:07.435338Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# show_cleaned_vis(df,\"yr_built\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "* No clear trend from this scatterplot\n",
    "\n",
    "\n",
    "* Seems like may houses built between 1940 - 1970, then major boom in early 2000s.\n",
    "\n",
    "\n",
    "* Some significant outliers with price\n",
    "\n",
    "\n",
    "**TO-DO**\n",
    "\n",
    "* Change regression line for scatter plot to distinguish the relationship\n",
    "\n",
    "\n",
    "* outliers\n",
    "\n",
    "\n",
    "* Compare to year sold - how old was the house at sale?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### yr_renovated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:07.463337Z",
     "start_time": "2021-06-03T00:02:07.449348Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# show_cleaned_vis(df,\"yr_renovated\", kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "* Number of houses not renovated significantly outweighs the number renovated\n",
    "\n",
    "\n",
    "* Graphs would be improved if we look only at the ones that were renovated (i.e. create new feature to distinguish reno vs. non-reno, then remake graphs\n",
    "\n",
    "\n",
    "* \n",
    "\n",
    "\n",
    "**TO-DO**\n",
    "\n",
    "* Feat Eng: reno/not reno; compare price to y/no\n",
    "\n",
    "\n",
    "* Significantly high outliers on reno properties\n",
    "\n",
    "\n",
    "* Convert to categorical, then use conditions to filter for more accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:07.478371Z",
     "start_time": "2021-06-03T00:02:07.465337Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# show_cleaned_vis(df,\"zipcode\", discrete=True, kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "* No linear relationship\n",
    "\n",
    "\n",
    "* \n",
    "\n",
    "\n",
    "* \n",
    "\n",
    "\n",
    "**TO-DO**\n",
    "\n",
    "* Investigate pricing per zip code\n",
    "\n",
    "\n",
    "* Create grouping based on zip code (groupby) for further analysis\n",
    "\n",
    "\n",
    "*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:07.494337Z",
     "start_time": "2021-06-03T00:02:07.481337Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# show_cleaned_vis(df,\"lat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "* most sold b/t 47.6 and 47.7\n",
    "\n",
    "\n",
    "* \n",
    "\n",
    "\n",
    "* \n",
    "\n",
    "\n",
    "**TO-DO**\n",
    "\n",
    "* compare # houses sold vs lat/long\n",
    "\n",
    "\n",
    "* geospatial visuals\n",
    "\n",
    "\n",
    "* FE: distance to major PoIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:07.510341Z",
     "start_time": "2021-06-03T00:02:07.497340Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# show_cleaned_vis(df,\"long\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "* See above\n",
    "\n",
    "\n",
    "* \n",
    "\n",
    "\n",
    "* \n",
    "\n",
    "\n",
    "**TO-DO**\n",
    "\n",
    "* \n",
    "\n",
    "\n",
    "* \n",
    "\n",
    "\n",
    "*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sqft_living15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:07.526341Z",
     "start_time": "2021-06-03T00:02:07.513338Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# show_cleaned_vis(df,\"sqft_living15\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "* Most properties sold w/ sqft b/t 1500/2000 \n",
    "\n",
    "\n",
    "* Price follows linear trend\n",
    "\n",
    "\n",
    "* \n",
    "\n",
    "\n",
    "**TO-DO**\n",
    "\n",
    "* Price outliers\n",
    "\n",
    "\n",
    "* H2 use this data effectively?\n",
    "\n",
    "\n",
    "*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sqft_lot15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:07.541339Z",
     "start_time": "2021-06-03T00:02:07.529338Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# show_cleaned_vis(df,\"sqft_lot15\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "* 0 SQFT - apartments?\n",
    "\n",
    "\n",
    "* Slight linear trend, but weak\n",
    "\n",
    "\n",
    "* Significant outliers with SQFT\n",
    "\n",
    "\n",
    "**TO-DO**\n",
    "\n",
    "* Investigate outlier\n",
    "\n",
    "\n",
    "* Confirm if apt bldgs\n",
    "\n",
    "\n",
    "*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the Region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not working - no time to fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:07.556340Z",
     "start_time": "2021-06-03T00:02:07.544341Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Creating geospatial view of King County, Washington\n",
    "\n",
    "# # Using Mapbox's API for geographical information\n",
    "# with open(r'C:\\Users\\bmcca\\.secret\\mapbox_api.json') as f:\n",
    "#     token = json.load(f)\n",
    "\n",
    "# open(r'C:\\Users\\bmcca\\.secret\\mapbox_api.json').read()\n",
    "    \n",
    "# token = token['token']\n",
    "\n",
    "# px.set_mapbox_access_token(token)\n",
    "\n",
    "# # Creating the map\n",
    "# fig = px.scatter_mapbox(df, lat= \"lat\", lon= \"long\", \n",
    "#                         color= 'price',\n",
    "#                         labels= {\"price\": \"Price ($) \",\n",
    "#                                  \"lat\":\"Latitude \",\n",
    "#                                  \"long\":\"Longitude \"},\n",
    "#                         hover_name = df[\"id\"],\n",
    "#                         color_continuous_scale=px.colors.sequential.Greys,\n",
    "#                         size_max=15, zoom=9.5, title='King County House Sales',\n",
    "#                         mapbox_style='light', width=1000, height=1200)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `'yrs_old'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine `'year_sold'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:07.588338Z",
     "start_time": "2021-06-03T00:02:07.558339Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['year_sold'] = df['date'].map(lambda x: x[:4])\n",
    "\n",
    "df['year_sold'] =  df['year_sold'].map(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:07.603340Z",
     "start_time": "2021-06-03T00:02:07.590338Z"
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:07.619339Z",
     "start_time": "2021-06-03T00:02:07.605337Z"
    }
   },
   "outputs": [],
   "source": [
    "df['year_sold'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:07.634337Z",
     "start_time": "2021-06-03T00:02:07.621338Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['year_sold'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate `'y_old_sold'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:07.650372Z",
     "start_time": "2021-06-03T00:02:07.636341Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['y_old_sold'] = df['year_sold'] - df['yr_built']\n",
    "df['y_old_sold'].describe()\n",
    "# min = -1 due to a house being sold before it was finished being built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:07.666373Z",
     "start_time": "2021-06-03T00:02:07.652341Z"
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:07.682371Z",
     "start_time": "2021-06-03T00:02:07.667338Z"
    }
   },
   "outputs": [],
   "source": [
    "df['y_old_sold'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:07.698351Z",
     "start_time": "2021-06-03T00:02:07.684338Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['y_old_sold'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `'was_renovated'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:07.713337Z",
     "start_time": "2021-06-03T00:02:07.701351Z"
    }
   },
   "outputs": [],
   "source": [
    "reno_y_n = np.where(df['yr_renovated']>0, 1, 0 )\n",
    "df = df.assign(was_renovated = reno_y_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:07.729337Z",
     "start_time": "2021-06-03T00:02:07.715338Z"
    }
   },
   "outputs": [],
   "source": [
    "df['was_renovated'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:07.744337Z",
     "start_time": "2021-06-03T00:02:07.731338Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `\"yrs_since_reno\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:07.760337Z",
     "start_time": "2021-06-03T00:02:07.746338Z"
    }
   },
   "outputs": [],
   "source": [
    "reno = df[df['was_renovated'] == 1]\n",
    "\n",
    "# print(reno['year_sold'].isna().sum())\n",
    "\n",
    "# print(reno['yr_renovated'].isna().sum())\n",
    "\n",
    "difference = reno['year_sold'] - reno['yr_renovated']\n",
    "\n",
    "difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:07.776344Z",
     "start_time": "2021-06-03T00:02:07.763340Z"
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:07.806339Z",
     "start_time": "2021-06-03T00:02:07.780340Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.assign(yrs_since_reno = difference)\n",
    "\n",
    "df['yrs_since_reno'].fillna(0, inplace=True)\n",
    "\n",
    "df['yrs_since_reno'].isnull().sum()\n",
    "\n",
    "df['yrs_since_reno'].describe()\n",
    "\n",
    "# min = -1 due to a house being sold before it was finished being built"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"`has_bsmnt`\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:07.838338Z",
     "start_time": "2021-06-03T00:02:07.810340Z"
    }
   },
   "outputs": [],
   "source": [
    "df['has_bsmnt'] = np.where(df['sqft_basement'] > 0, 1, 0)\n",
    "\n",
    "display(df['has_bsmnt'].describe(), df['has_bsmnt'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining Correlations with Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:04:12.805857Z",
     "start_time": "2021-06-03T00:04:12.772833Z"
    }
   },
   "outputs": [],
   "source": [
    "## Determining each feature's relationship with price\n",
    "\n",
    "df_corr = df.drop(['price', 'id', 'lat','long'], axis=1).corrwith(df['price']).sort_values(ascending=False)\n",
    "display(df_corr[0:5],df_corr[-6:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:04:13.864798Z",
     "start_time": "2021-06-03T00:04:13.802799Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Get the correlation matrix for the data (without the target)\n",
    "corr = df.drop('price',axis=1).corr()\n",
    "corr.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ƒ: `\"corr_val\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:04:14.815281Z",
     "start_time": "2021-06-03T00:04:14.796247Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Create \"corr_val\" function\n",
    "\n",
    "def corr_val(df,figsize=(15,15),cmap=\"OrRd\",):\n",
    "    \n",
    "    # Calculate correlations\n",
    "    corr = df.corr()\n",
    "       \n",
    "    # Create a mask of the same size as our correlation data\n",
    "    mask = np.zeros_like(corr)\n",
    "    \n",
    "    # Set the upper values of the numpy array to \"True\" to ignore them\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Mask=mask to hide the upper-right half of values (otherwise mirrored)\n",
    "    sns.heatmap(corr, annot=True,cmap=\"Reds\",mask=mask)\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:04:20.194889Z",
     "start_time": "2021-06-03T00:04:17.892918Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "corr_val(df.drop('price',axis=1), figsize=(20,20));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:04:20.240889Z",
     "start_time": "2021-06-03T00:04:20.197889Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Correlation results ignoring (most) duplicate values\n",
    "df_corr_results = df.corr().unstack().sort_values(ascending=False).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:04:24.555498Z",
     "start_time": "2021-06-03T00:04:24.536470Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Show strongest postive and negative correlations\n",
    "display(df_corr_results[1:11], df_corr_results[-11:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:03:46.601560Z",
     "start_time": "2021-06-03T00:03:45.983562Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dropping columns to address multicollinearity\n",
    "\n",
    "df.drop(['yr_renovated','sqft_basement','sqft_above'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:14.577350Z",
     "start_time": "2021-06-03T00:02:11.728338Z"
    }
   },
   "outputs": [],
   "source": [
    "# Rerunning model\n",
    "\n",
    "corr_val(df.drop('price',axis=1), figsize=(20,20));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:14.624342Z",
     "start_time": "2021-06-03T00:02:14.579345Z"
    }
   },
   "outputs": [],
   "source": [
    "# Correlation results ignoring (most) duplicate values\n",
    "df_corr_results = df.corr().unstack().sort_values(ascending=False).drop_duplicates()\n",
    "\n",
    "# Show strongest postive and negative correlations\n",
    "display(df_corr_results[1:11], df_corr_results[-11:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Top 10 Positive Relationships**\n",
    ">* Nothing too surprising as most of the matches are intuitively related.\n",
    ">  * E.g. \"yr_renovated\" and \"was_renovated\" have a nearly-perfect positive correlation as \"was_renovated\" is determined by \"yr_renovated\" in our feature engineering.\n",
    ">\n",
    ">\n",
    ">* Two interesting relationships would be:\n",
    ">  * The living space (ft^2) and grade\n",
    ">    * Indicates that a larger house has a higher grade\n",
    "> * The living space (ft^2) of the 15 nearest houses sold\n",
    ">   * Indicates a larger area above ground (ft^2)\n",
    ">    * Perhaps larger houses are more likely to be nearby each other?\n",
    "***\n",
    "**Top 10 Negative Relationships**\n",
    ">* Older houses may have fewer bathrooms\n",
    ">* Older houses may have fewer floors\n",
    ">* Older houses have a lower grade\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Statistical Testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *One-Way ANOVA*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing `'condition'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* H0: The feature \"condition\" does not have an effect on price.\n",
    "\n",
    "* Ha: The feature \"condition\" does  have an effect on price.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:14.655340Z",
     "start_time": "2021-06-03T00:02:14.628340Z"
    }
   },
   "outputs": [],
   "source": [
    "## Defining variables for the prices of each value of conditions\n",
    "\n",
    "condition_1 = df.loc[df['condition'] == 1, 'price']\n",
    "condition_2 = df.loc[df['condition'] == 2, 'price']\n",
    "condition_3 = df.loc[df['condition'] == 3, 'price']\n",
    "condition_4 = df.loc[df['condition'] == 4, 'price']\n",
    "condition_5 = df.loc[df['condition'] == 5, 'price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:14.671338Z",
     "start_time": "2021-06-03T00:02:14.658340Z"
    }
   },
   "outputs": [],
   "source": [
    "## Running ANOVA test to determine significance\n",
    "\n",
    "# Define alpha\n",
    "alpha = .05\n",
    "\n",
    "# Run test\n",
    "result = stats.f_oneway(condition_1, condition_2, condition_3, condition_4, condition_5)\n",
    "f_stat, p_value = result\n",
    "\n",
    "# Evaluate if significant or not\n",
    "if p_value < .05:\n",
    "    print(f'The condition of a home is statistically significant with a p-value of {p_value}.')\n",
    "    \n",
    "else:\n",
    "     print(f'The condition of a home is not statistically significant with a p-value of {p_value}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:15.152337Z",
     "start_time": "2021-06-03T00:02:14.674338Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show visual of conclusion\n",
    "\n",
    "sns.barplot(data=df, x= 'condition', y = 'price', ci=68)\n",
    "plt.suptitle(\"Waterfront's Affect on Price\", size = (20))\n",
    "plt.xlabel('Condition')\n",
    "plt.ylabel('Price ($)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The t-test shows that the condition of a house is statistically significant due to the p-value below our alpha of .05.\n",
    ">\n",
    "> This means that the quality of a house will have a statistically significant impact on the sell price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Two-Sample T-Tests*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing  `'waterfront'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* H0: The feature \"waterfront\" does not have an effect on price.\n",
    "\n",
    "* Ha: The feature \"waterfront\" does  have an effect on price.\n",
    "\n",
    "\n",
    "* Alpha = .05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:15.168366Z",
     "start_time": "2021-06-03T00:02:15.155338Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set variables to represent whether or not a property is listed as 'waterfront.'\n",
    "\n",
    "wf_yes = df.loc[df['waterfront'] == 1, 'price']\n",
    "wf_no = df.loc[df['waterfront'] == 0, 'price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:15.199337Z",
     "start_time": "2021-06-03T00:02:15.170351Z"
    }
   },
   "outputs": [],
   "source": [
    "ttest_review(wf_yes, wf_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:15.526337Z",
     "start_time": "2021-06-03T00:02:15.201339Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show visual of conclusion\n",
    "\n",
    "sns.barplot(data=df, x= 'waterfront', y = 'price', ci=68);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The t-test shows that waterfront is statistically significant due to the p-value below our alpha of .05.\n",
    ">\n",
    "> This means that having a house on the waterfront will have a significant impact on the sell price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing `\"was_renovated\"` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hypotheses**\n",
    "\n",
    "---\n",
    ">**H0:** There is not a statistically significant difference in price in homes with a basement than those without.\n",
    ">\n",
    ">**HA:** There is a statistically significant difference in price in homes with a basement than those without.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:15.541338Z",
     "start_time": "2021-06-03T00:02:15.528338Z"
    }
   },
   "outputs": [],
   "source": [
    "reno_y = df.loc[df['was_renovated'] == 1, 'price']\n",
    "reno_n = df.loc[df['was_renovated'] == 0, 'price']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:15.557338Z",
     "start_time": "2021-06-03T00:02:15.543338Z"
    }
   },
   "outputs": [],
   "source": [
    "ttest_review(reno_y, reno_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:15.913346Z",
     "start_time": "2021-06-03T00:02:15.565341Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show visual of conclusion\n",
    "\n",
    "sns.barplot(data=df, x= 'was_renovated', y = 'price', ci=68);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The t-test shows that having a basement is statistically significant due to the p-value below our alpha of .05.\n",
    ">\n",
    "> This means that having a house with a basement will have a significant impact on the sell price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:15.944337Z",
     "start_time": "2021-06-03T00:02:15.917337Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ƒ: `diagnose_model`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* Create a function to:\n",
    ">  * Display the summary details of the model\n",
    ">  * Create a scatter plot of the predictions\n",
    ">    * Used for determining homoscedasticity\n",
    ">  * Create a Q-Q plot of the residuals of the model\n",
    ">    * Used to determine the normality of the residuals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:15.959368Z",
     "start_time": "2021-06-03T00:02:15.946336Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def diagnose_model(model, figsize=(10,5)):\n",
    "    \"\"\" ---\n",
    "    \n",
    "    Argument:\n",
    "        * model: provide the linear regression model for diagnostics\n",
    "    \n",
    "    Keyword Argument:\n",
    "        * figsize: default (10,5); can increase/decrease for larger/smaller\n",
    "    ---\n",
    "    \n",
    "    * Display the summary details of the provided model\n",
    "    * Create two scatter plots to test assumptions of linearity\n",
    "        * Predictions: verifying homoscedasticity (no cone-shapes)\n",
    "        * Residuals: confirming normal distribution of residuals\n",
    "    ---\n",
    "    \n",
    "    \"\"\"\n",
    "    display(model.summary())\n",
    "    \n",
    "    fig, axes = plt.subplots(ncols=2, figsize=figsize)\n",
    "\n",
    "    axes[0].scatter(model.predict(), model.resid)\n",
    "    axes[0].axhline()\n",
    "    axes[0].set_xlabel('Model Predictions')\n",
    "    axes[0].set_ylabel('Model Residuals')\n",
    "    axes[0].set_title('Testing for Homoscedasticity')\n",
    "\n",
    "    sms.graphics.qqplot(data=model.resid, fit=True, line = \"45\", ax=axes[1])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T20:59:23.235155Z",
     "start_time": "2021-05-31T20:59:23.224158Z"
    }
   },
   "source": [
    "## ƒ: `plot_param_coef`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* Create a function to:\n",
    ">  * Get the model's coefficients as a series\n",
    ">  * Plot a figure to show the coefficients in descending order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:15.974338Z",
     "start_time": "2021-06-03T00:02:15.961341Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def plot_param_coef(model, kind = 'barh', figsize = (10,5)):\n",
    "    ''' ---\n",
    "    \n",
    "    * Plotting a figure to visualize parameter coefficients\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    * Args:\n",
    "        * Model: linear regression model details to plot\n",
    "        \n",
    "    * Kwargs:\n",
    "        * Kind (default 'barh'): allows different types of plots\n",
    "        * Size (default (10,10)): allows for different sizes\n",
    "    ---\n",
    "    \n",
    "    '''\n",
    "    # Plotting figure to visualize parameter coefficients\n",
    "\n",
    "    ## Getting coefficients as a Series\n",
    "    params = model.params[1:]\n",
    "    params.sort_values(inplace=True)\n",
    "\n",
    "    plt.figure(figsize=figsize) # Used if large number of params\n",
    "    ax = params.plot(kind=kind)\n",
    "    ax.axvline()\n",
    "    ax.set_xlabel('Coefficient')\n",
    "    ax.set_ylabel('Features')\n",
    "    ax.set_title('Comparing Feature Coefficients')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ƒ: `plot_p_values`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* Create a function to:\n",
    ">  * Get the model's p-values as a series\n",
    ">  * Plot a figure to show the p-values in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:15.990338Z",
     "start_time": "2021-06-03T00:02:15.976343Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def plot_p_values(model, kind = 'barh', size = None, alpha = .05):\n",
    "    ''' ---\n",
    "    \n",
    "    * Plots a figure to visualize parameter p-values exceeding stated alpha.\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    * Args:\n",
    "        * Model: linear regression model details to plot\n",
    "        \n",
    "    * Kwargs:\n",
    "        * Kind (default 'barh'): allows different types of plots\n",
    "        * Size (default None): allows for different sizes\n",
    "    ---\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    pv = model.pvalues[1:]\n",
    "    pv_high = pv[pv > alpha]\n",
    "    pv_low = pv[pv <= alpha]\n",
    "    pv_high.sort_values(ascending=False, inplace=True)\n",
    "    \n",
    "    if len(pv_high) > 0:\n",
    "        plt.figure(figsize=size) # Used if large number of params\n",
    "        ax = pv_high.plot(kind=kind)\n",
    "        ax = pv_low.plot(kind=kind)\n",
    "        ax.axvline()\n",
    "        plt.suptitle(f'P-Values')\n",
    "        \n",
    "    if len(pv_low) > 0:\n",
    "        plt.figure(figsize=size) # Used if large number of params\n",
    "        ax = pv_low.plot(kind=kind)\n",
    "        ax.axvline()\n",
    "        plt.suptitle(f'P-Values Below {alpha}')        \n",
    "        \n",
    "#     else:\n",
    "#         print(f'There are no p-values above {alpha}.')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ƒ: `review_model` (Combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:16.005338Z",
     "start_time": "2021-06-03T00:02:15.992340Z"
    }
   },
   "outputs": [],
   "source": [
    "def review_model(model):\n",
    "    '''---\n",
    "    \n",
    "    Combines earlier functions into one all-purpose function for reviewing\n",
    "    model performance.\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    Arg:\n",
    "        * model: Specify model to review.\n",
    "        \n",
    "    ---'''\n",
    "    \n",
    "    diagnose_model(model)\n",
    "    \n",
    "    plot_param_coef(model)\n",
    "    \n",
    "    plot_p_values(model)\n",
    "    \n",
    "    return    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ƒ: `identify_high_pv` (deprecated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* Create a function to:\n",
    ">  * Identify any coefficients with p-values higher than the stated alpha threshold\n",
    ">  * If there are any, then create a dictionary to show the values\n",
    ">  * If there are no p-values exceeding the threshold, then print a statement saying there are none.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:16.021343Z",
     "start_time": "2021-06-03T00:02:16.007339Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def identify_high_pv(model, alpha = .05):\n",
    "    '''---\n",
    "    \n",
    "    Identifies any coefficients with p-values higher than the stated alpha threshold.\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    Args:\n",
    "        * model: linear regression model\n",
    "        \n",
    "    Kwargs:\n",
    "        * alpha (default .05): specify alpha for significance\n",
    "        \n",
    "    ---\n",
    "    \n",
    "    '''\n",
    "\n",
    "    pv = model.pvalues\n",
    "\n",
    "    pv[pv > alpha].sort_values(ascending=False)\n",
    "\n",
    "    high_p = {}\n",
    "\n",
    "    for idx, val in zip(pv.index, pv.values):\n",
    "        if val > alpha:\n",
    "            high_p.update({idx : round(val, 2)})\n",
    "\n",
    "    if len(high_p) == 0:\n",
    "        print(\"There are no p-values exceeding .05.\")\n",
    "    \n",
    "    else:\n",
    "        print(f'The features with p-values exceeing .05 are: {high_p}')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functionizing Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Variables: Continuous and Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GOAL:**\n",
    "\n",
    "* Create one list for continuous variables\n",
    "* Create one list for categorical variables\n",
    "\n",
    "***Why:*** I think I was trying to build variables for use in modeling (using .join to create a variable for use in the equation\n",
    " * Given top 5 highest correlated features, run reg on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:16.053341Z",
     "start_time": "2021-06-03T00:02:16.025344Z"
    }
   },
   "outputs": [],
   "source": [
    "## Determining each feature's relationship with price\n",
    "\n",
    "df_corr = df.drop(['price', 'id', 'lat','long'], axis=1).corrwith(df['price']).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:16.069339Z",
     "start_time": "2021-06-03T00:02:16.056342Z"
    }
   },
   "outputs": [],
   "source": [
    "## Need to get the function names via .index.values\n",
    "\n",
    "df_corr.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:16.085338Z",
     "start_time": "2021-06-03T00:02:16.071339Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Creating variable 'features' for continuous variables for use in modeling\n",
    "\n",
    "# var_cont = ['sqft_living', 'sqft_lot', 'sqft_above',\\\n",
    "#             'sqft_basement', 'yr_built', 'yr_renovated', 'sqft_living15',\\\n",
    "#             'sqft_lot15']\n",
    "\n",
    "# corr_cont = []\n",
    "\n",
    "# ## Not working - need the index number for the list created from .index.values\n",
    "# for i in var_cont:\n",
    "#     df_corr.index.values[i]\n",
    "#     corr_cont.append(rounded)\n",
    "    \n",
    "# # display(corr_cont)\n",
    "\n",
    "# cont_features = '+'.join(list(corr_cont))\n",
    "\n",
    "# cont_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:16.893336Z",
     "start_time": "2021-06-03T00:02:16.087338Z"
    }
   },
   "outputs": [],
   "source": [
    "categorical_features = ['was_renovated','has_bsmnt', 'waterfront']\n",
    "\n",
    "continuous_features = ['y_old_sold','yrs_since_reno', 'bedrooms', 'bathrooms',\n",
    "                       'condition','grade', 'floors']\n",
    "\n",
    "cont_features = '+'.join(continuous_features)\n",
    "\n",
    "cat_features = '+'.join([f'C({x})' for x in categorical_features])\n",
    "\n",
    "f = f'price~+{cont_features}+{cat_features}'\n",
    "\n",
    "print(f)\n",
    "\n",
    "model_test_var = smf.ols(formula=f, data=df).fit()\n",
    "\n",
    "diagnose_model(model_test_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "\n",
    "* R^2: ~.6, less than target of .75\n",
    "\n",
    "* Residual plots show heteroscedasticity\n",
    "\n",
    "* Q-Q Plot shows non-normal residuals\n",
    "\n",
    "* Changes: remove outliers and retest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - W/O Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✨ Cleaning 'Price' Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:16.909335Z",
     "start_time": "2021-06-03T00:02:16.895338Z"
    }
   },
   "outputs": [],
   "source": [
    "## Remove outliers from price \n",
    "idx_outs = find_outliers_z(df['price'])\n",
    "df_clean = df[~idx_outs].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:16.987337Z",
     "start_time": "2021-06-03T00:02:16.911337Z"
    }
   },
   "outputs": [],
   "source": [
    "df_clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:17.083338Z",
     "start_time": "2021-06-03T00:02:16.990338Z"
    }
   },
   "outputs": [],
   "source": [
    "## Remove outliers from bedrooms\n",
    "idx_outs = find_outliers_z(df_clean['bedrooms'])\n",
    "df_clean = df_clean[~idx_outs].copy()\n",
    "\n",
    "df_clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:17.813351Z",
     "start_time": "2021-06-03T00:02:17.085339Z"
    }
   },
   "outputs": [],
   "source": [
    "categorical_features = ['was_renovated','has_bsmnt', 'waterfront']\n",
    "\n",
    "continuous_features = ['y_old_sold','yrs_since_reno', 'bedrooms', 'bathrooms',\n",
    "                       'condition','grade', 'floors']\n",
    "\n",
    "cont_features = '+'.join(continuous_features)\n",
    "\n",
    "cat_features = '+'.join([f'C({x})' for x in categorical_features])\n",
    "\n",
    "f = f'price~+{cont_features}+{cat_features}'\n",
    "\n",
    "print(f)\n",
    "\n",
    "model_clean = smf.ols(formula=f, data=df_clean).fit()\n",
    "\n",
    "diagnose_model(model_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "\n",
    "* R^2: ~.59, less than target of .75\n",
    "\n",
    "* Residual plots show somewhat homoscedasticity\n",
    "\n",
    "* Q-Q Plot shows more normal residuals (vs. earlier plot)\n",
    "\n",
    "* Changes: add zipcode "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - w/ Zip Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:18.838339Z",
     "start_time": "2021-06-03T00:02:17.815350Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "categorical_features = ['was_renovated','has_bsmnt', 'waterfront', 'zipcode']\n",
    "\n",
    "continuous_features = ['y_old_sold','yrs_since_reno', 'bedrooms', 'bathrooms',\n",
    "                       'condition','grade', 'floors']\n",
    "\n",
    "cont_features = '+'.join(continuous_features)\n",
    "\n",
    "cat_features = '+'.join([f'C({x})' for x in categorical_features])\n",
    "\n",
    "f = f'price~+{cont_features}+{cat_features}'\n",
    "\n",
    "print(f)\n",
    "\n",
    "model_clean = smf.ols(formula=f, data=df_clean).fit()\n",
    "\n",
    "diagnose_model(model_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "\n",
    "* R^2: ~.77, greater than target of .75\n",
    "\n",
    "* Residual plots show somewhat homoscedasticity\n",
    "\n",
    "* Q-Q Plot shows more normal residuals (vs. earlier plot)\n",
    "\n",
    "* Changes: remove features with p-values higher than .05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:19.699337Z",
     "start_time": "2021-06-03T00:02:18.840337Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "categorical_features = ['was_renovated','waterfront', 'zipcode']\n",
    "\n",
    "continuous_features = ['y_old_sold','yrs_since_reno', 'bedrooms', 'bathrooms',\n",
    "                       'condition','grade']\n",
    "\n",
    "cont_features = '+'.join(continuous_features)\n",
    "\n",
    "cat_features = '+'.join([f'C({x})' for x in categorical_features])\n",
    "\n",
    "f = f'price~+{cont_features}+{cat_features}'\n",
    "\n",
    "print(f)\n",
    "\n",
    "model_clean = smf.ols(formula=f, data=df_clean).fit()\n",
    "\n",
    "diagnose_model(model_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:22.080339Z",
     "start_time": "2021-06-03T00:02:19.702339Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '{:,.2f}'.format(x))\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# s.apply(lambda x: '{:,}'.format(x))\n",
    "\n",
    "coeff_clean = model_clean.params.sort_values(ascending=False)\n",
    "coeff_clean.plot(kind='barh');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:22.095338Z",
     "start_time": "2021-06-03T00:02:22.082341Z"
    }
   },
   "outputs": [],
   "source": [
    "coeff_clean.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations\n",
    "\n",
    "* Add bathroom\n",
    "* Use high-quality materials in renovations\n",
    "* Zip code will have large effect on price, but beyond homeowner's control\n",
    "* Also consider adding bedrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:23.009351Z",
     "start_time": "2021-06-03T00:02:22.098340Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.regplot(data=df_clean, x=\"bathrooms\", y='price');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:23.878343Z",
     "start_time": "2021-06-03T00:02:23.012343Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.regplot(data=df_clean, x=\"bedrooms\", y='price');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:24.778338Z",
     "start_time": "2021-06-03T00:02:23.880346Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.regplot(data=df_clean, x=\"grade\", y='price');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:28.023337Z",
     "start_time": "2021-06-03T00:02:24.780336Z"
    }
   },
   "outputs": [],
   "source": [
    "fg = sns.catplot(data=df_clean, x=\"zipcode\", y='price', aspect=2.5, height=5)\n",
    "fg.ax.set_xticklabels(fg.ax.get_xticklabels(), rotation=45, ha='right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Notebook - Continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:28.039338Z",
     "start_time": "2021-06-03T00:02:28.026340Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# f = f'price~+y_old_sold+C(was_renovated)+yrs_since_reno+C(has_bsmnt)'\n",
    "\n",
    "# model_eng_feat = smf.ols(formula=f, data=df_clean).fit()\n",
    "\n",
    "# var_cont = ['sqft_living', 'sqft_lot', 'yr_built', 'sqft_living15','sqft_lot15']\n",
    "\n",
    "# cont_features = '+'.join(list(var_cont))\n",
    "\n",
    "# f = f'price~{cont_features}'\n",
    "\n",
    "# model_test_var = smf.ols(formula=f, data=df_clean).fit()\n",
    "\n",
    "# diagnose_model(model_test_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:28.209372Z",
     "start_time": "2021-06-03T00:02:28.041350Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = 'price~+y_old_sold+C(was_renovated)+yrs_since_reno+C(has_bsmnt)'\n",
    "\n",
    "model_eng_feat = smf.ols(formula=f, data=df_clean).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:29.159336Z",
     "start_time": "2021-06-03T00:02:28.211341Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "review_model(model_eng_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:29.174337Z",
     "start_time": "2021-06-03T00:02:29.161350Z"
    }
   },
   "outputs": [],
   "source": [
    "df.columns.drop(['price', 'id', 'date', 'lat', 'long'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:29.206335Z",
     "start_time": "2021-06-03T00:02:29.176340Z"
    }
   },
   "outputs": [],
   "source": [
    "idx_outs = find_outliers_z(df['price'])\n",
    "df_clean = df[~idx_outs].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:29.252337Z",
     "start_time": "2021-06-03T00:02:29.208337Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f = 'price~bedrooms+sqft_living+grade'\n",
    "\n",
    "model_no_zip = smf.ols(formula=f, data=df).fit()\n",
    "\n",
    "display(model_no_zip.summary());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:29.267338Z",
     "start_time": "2021-06-03T00:02:29.255341Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Bad idea - don't do!\n",
    "\n",
    "# f = 'price~bedrooms+bathrooms+sqft_living+sqft_lot+floors+sqft_above\\\n",
    "#     +sqft_basement+yr_built+yr_renovated+sqft_living15+sqft_lot15+year_sold\\\n",
    "#     +y_old_sold+was_renovated+yrs_since_reno+C(waterfront)+C(grade)\\\n",
    "#     +C(waterfront)+C(view)+C(condition)+C(grade)+C(zipcode)+C(was_renovated)\\\n",
    "#     +C(has_bsmnt)'\n",
    "\n",
    "# model_no_zip = smf.ols(formula=f, data=df).fit()\n",
    "\n",
    "# diagnose_model(model_no_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:29.469343Z",
     "start_time": "2021-06-03T00:02:29.269338Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_param_coef(model_no_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:29.687337Z",
     "start_time": "2021-06-03T00:02:29.471338Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_p_values(model_no_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:30.478371Z",
     "start_time": "2021-06-03T00:02:29.689338Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "review_model(model_no_zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    ">* **R2:** This model only explains 58% of the variation of the data using the selected features. \n",
    "\n",
    "\n",
    ">* **Coefficients:** According to this model, the \"Waterfront\" feature indicates the strongest impact on determining price.\n",
    "\n",
    "\n",
    ">* **P-Values:** All p-values are below .000, indicating they are statistically significant.\n",
    "\n",
    "\n",
    ">* **Homoscedasticity:** Our scatter plot of the predictions has a cone-shape, indicating the error term in our model is inconsistent.\n",
    "\n",
    "\n",
    ">* **Normality of Residuals:** Our second scatter plot violates the assumption of the normality of the residuals.\n",
    "\n",
    "\n",
    ">* **Overall:** the model violates the assumptions of Homoscedasticity and the Normality of Residuals. The model is not proper and could result in improper inferences.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model (Zipcode as Cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:31.274343Z",
     "start_time": "2021-06-03T00:02:30.480339Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Creating a model that includes Zipcode as a category\n",
    "\n",
    "f = 'price~bedrooms+sqft_living+grade+waterfront+C(zipcode)'\n",
    "\n",
    "model_w_c_zip = smf.ols(formula=f, data=df_clean).fit()\n",
    "\n",
    "diagnose_model(model_w_c_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:31.290370Z",
     "start_time": "2021-06-03T00:02:31.277352Z"
    }
   },
   "outputs": [],
   "source": [
    "identify_high_pv(model_w_c_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:33.840378Z",
     "start_time": "2021-06-03T00:02:31.293340Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_param_coef(model_w_c_zip, figsize=(10,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:34.728370Z",
     "start_time": "2021-06-03T00:02:33.843338Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.regplot(data=df_clean,x='sqft_living',y='price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    ">* **R2:** This model explains 78% of the data, which is a significant increase from the first.\n",
    "\n",
    "\n",
    ">* **Coefficients:** According to this model, the \"Zipcode 98039\" feature indicates the strongest impact on determining price. Having a home in that zip code has the highest impact on price. Additionally, this indicates that zip code may be one of the stronger predictors for our modeling.\n",
    "\n",
    "\n",
    ">* **P-Values:** \n",
    "\n",
    ">* **Homoscedasticity:** Our scatter plot of the predictions has a cone-shape, indicating the error term in our model is inconsistent.\n",
    "\n",
    "\n",
    ">* **Normality of Residuals:** Our second scatter plot violates the assumption of the normality of the residuals.\n",
    "\n",
    "\n",
    ">* **Overall:** the model violates the assumptions of Homoscedasticity and the Normality of Residuals. The model is not proper and could result in improper inferences.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functionizing Model - Testing Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:35.308337Z",
     "start_time": "2021-06-03T00:02:34.730340Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "var_cont = ['sqft_living', 'sqft_lot', 'yr_built', 'sqft_living15','sqft_lot15']\n",
    "\n",
    "cont_features = '+'.join(list(var_cont))\n",
    "\n",
    "f = f'price~{cont_features}'\n",
    "\n",
    "model_test_var = smf.ols(formula=f, data=df_clean).fit()\n",
    "\n",
    "diagnose_model(model_test_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:35.772336Z",
     "start_time": "2021-06-03T00:02:35.310344Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "var_cont = ['sqft_living', 'yr_built', 'sqft_living15','sqft_lot15']\n",
    "\n",
    "cont_features = '+'.join(list(var_cont))\n",
    "\n",
    "f = f'price~{cont_features}'\n",
    "\n",
    "model_test_var = smf.ols(formula=f, data=df_clean).fit()\n",
    "\n",
    "diagnose_model(model_test_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:35.975339Z",
     "start_time": "2021-06-03T00:02:35.774339Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_param_coef(model_test_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Lists: Continuous and Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GOAL:**\n",
    "\n",
    "* Create one list for continuous variables\n",
    "* Create one list for categorical variables\n",
    "\n",
    "***Why:*** I think I was trying to build variables for use in modeling (using .join to create a variable for use in the equation\n",
    " * Given top 5 highest correlated features, run reg on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:36.006339Z",
     "start_time": "2021-06-03T00:02:35.978339Z"
    }
   },
   "outputs": [],
   "source": [
    "## Determining each feature's relationship with price\n",
    "\n",
    "df_corr = df.drop(['price', 'id', 'lat','long'], axis=1).corrwith(df['price']).sort_values(ascending=False)\n",
    "display(df_corr[0:5],df_corr[-6:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:36.022337Z",
     "start_time": "2021-06-03T00:02:36.008338Z"
    }
   },
   "outputs": [],
   "source": [
    "# idx_top_5 = list(df_corr.index.values)\n",
    "# idx_top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:36.038337Z",
     "start_time": "2021-06-03T00:02:36.025337Z"
    }
   },
   "outputs": [],
   "source": [
    "# '+'.join(idx_top_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✨ Needs Fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:36.054337Z",
     "start_time": "2021-06-03T00:02:36.040338Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Creating variable 'features' for continuous variables for use in modeling\n",
    "\n",
    "# var_cont = ['sqft_living', 'sqft_lot', 'sqft_above',\\\n",
    "#             'sqft_basement', 'yr_built', 'yr_renovated', 'sqft_living15',\\\n",
    "#             'sqft_lot15']\n",
    "# corr_cont = []\n",
    "\n",
    "# for i in var_cont:\n",
    "#     rounded = round(df_corr[i],2).astype(str)\n",
    "#     corr_cont.append(rounded)\n",
    "    \n",
    "# # display(corr_cont)\n",
    "\n",
    "# features = '+'.join(list(corr_cont))\n",
    "\n",
    "# features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:36.069370Z",
     "start_time": "2021-06-03T00:02:36.056340Z"
    }
   },
   "outputs": [],
   "source": [
    "# Getting feature names for looping\n",
    "\n",
    "col_names = df_clean.columns.values\n",
    "\n",
    "feat_names = []\n",
    "\n",
    "for name in col_names:\n",
    "    if name == 'price' or 'id' or \"lat\" or 'long':\n",
    "        feat_names.append(name)\n",
    "\n",
    "display(feat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:37.549367Z",
     "start_time": "2021-06-03T00:02:36.071339Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Creating loop to evaluate r squared of each individual feature.\n",
    "\n",
    "for name in feat_names:\n",
    "    f = f'price~{name}'\n",
    "\n",
    "    model = smf.ols(formula=f, data=df_clean).fit()\n",
    "\n",
    "#     if model.pvalues < .05:\n",
    "    if model.rsquared >= .75:\n",
    "        print(f'The feature {name} indicates a strong effect with an R-Squared of {round(model.rsquared,2)}')\n",
    "\n",
    "    if model.rsquared < .5:\n",
    "        print(f'The feature {name} indicates a weak effect with an R-Squared of {round(model.rsquared,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:38.916386Z",
     "start_time": "2021-06-03T00:02:37.551337Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Creating loop to evaluate r squared of each individual feature.\n",
    "\n",
    "high_r = []\n",
    "\n",
    "low_r = []\n",
    "\n",
    "for name in feat_names:\n",
    "    f = f'price~{name}'\n",
    "\n",
    "    model = smf.ols(formula=f, data=df_clean).fit()\n",
    "\n",
    "#     if model.pvalues < .05:\n",
    "    if model.rsquared >= .75:\n",
    "        high_r.append([name, round(model.rsquared,2)])\n",
    "#         print(f'The feature {name} indicates a strong effect with an R-Squared of {round(model.rsquared,2)}')\n",
    "\n",
    "    if model.rsquared < .5:\n",
    "        low_r.append([name, round(model.rsquared,2)])\n",
    "#         print(f'The feature {name} indicates a weak effect with an R-Squared of {round(model.rsquared,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:38.932372Z",
     "start_time": "2021-06-03T00:02:38.918337Z"
    }
   },
   "outputs": [],
   "source": [
    "display(high_r, low_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:39.415341Z",
     "start_time": "2021-06-03T00:02:38.935351Z"
    }
   },
   "outputs": [],
   "source": [
    "f = 'price~grade+sqft_living+sqft_living15'\n",
    "\n",
    "model = smf.ols(formula=f, data=df_clean).fit()\n",
    "\n",
    "diagnose_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:39.447338Z",
     "start_time": "2021-06-03T00:02:39.417338Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:39.900337Z",
     "start_time": "2021-06-03T00:02:39.449338Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f = 'price~y_old_sold+was_renovated+has_bsmnt'\n",
    "\n",
    "model = smf.ols(formula=f, data=df_clean).fit()\n",
    "\n",
    "diagnose_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deprecated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deprecated: Date: Convert from \"object\" to \"datetime\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:39.915337Z",
     "start_time": "2021-06-03T00:02:39.902337Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# # Inspect data for \"date\" column\n",
    "\n",
    "# df['date'].iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:39.931337Z",
     "start_time": "2021-06-03T00:02:39.917351Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# # Select first 7 characters for each element in column\n",
    "\n",
    "# df['date'] = [x[:8] for x in df['date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:39.947339Z",
     "start_time": "2021-06-03T00:02:39.933341Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# # Convert to datetime and sort\n",
    "\n",
    "# df['date'] = pd.to_datetime(df['date'], format='%Y%m%d')\n",
    "# df['date'] = df['date'].sort_values()\n",
    "# df['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:39.963341Z",
     "start_time": "2021-06-03T00:02:39.949339Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for col in df:\n",
    "#     try:\n",
    "#         sns.boxplot(data=df[col]);\n",
    "#     except Exception:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:39.979340Z",
     "start_time": "2021-06-03T00:02:39.966357Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# def plot_hist_regplot_gs(df,column,target='price',\n",
    "#                      figsize=(12,5),style='seaborn-notebook',\n",
    "#                      line_kws={'color':'black','ls':':'},\n",
    "#                     scatter_kws={'s':3},cat=False):\n",
    "    \n",
    "#     with plt.style.context(style):\n",
    "#         fig = plt.figure(figsize=figsize,constrained_layout=True)\n",
    "\n",
    "#         gs = fig.add_gridspec(nrows=2,ncols=3,)\n",
    "#         ax1 = fig.add_subplot(gs[0,2])\n",
    "#         ax2 = fig.add_subplot(gs[1,2])\n",
    "#         ax3 = fig.add_subplot(gs[:2,:2])\n",
    "        \n",
    "\n",
    "#         if cat == True:\n",
    "# #             sns.barplot(data=df,x=column, y=target, ax=ax3,palette='dark',\n",
    "# #                         estimator=np.median)\n",
    "#             sns.stripplot(data=df,x=column,size=3, y=target,alpha=0.5, ax=ax3,palette='dark')\n",
    "#             hist_discrete = True\n",
    "#         else:\n",
    "#             # regplot\n",
    "#             hist_discrete = None\n",
    "#             sns.regplot(data=df,x=column, y=target, ax=ax3,\n",
    "#                         line_kws=line_kws, scatter_kws=scatter_kws)\n",
    "#         ## Histogram\n",
    "#         sns.histplot(data=df, x=column,stat='probability',discrete=hist_discrete,\n",
    "#                      ax=ax1)\n",
    "                \n",
    "#         ## boxplot\n",
    "#         sns.boxplot(data=df,x=column,ax=ax2)\n",
    "        \n",
    "#     fig.suptitle(f'Inspecting {column} vs {target}',y=1.05)\n",
    "        \n",
    "#     return fig, (ax1,ax2,ax3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing duplicate IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:39.995341Z",
     "start_time": "2021-06-03T00:02:39.981341Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = df.sort_values(['id','date'],ascending=False)\n",
    "# df[df.duplicated('id',keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T00:02:40.011342Z",
     "start_time": "2021-06-03T00:02:39.998358Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Keeping the most recent date\n",
    "# df.drop_duplicates(keep='first',subset=['id'],inplace=True)\n",
    "\n",
    "# # ## sort by index and drop uneeded columns\n",
    "# # df.sort_index(inplace=True)\n",
    "\n",
    "# ## Confirming duplicates removed\n",
    "# df[df.duplicated('id',keep=False)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env-bmc)",
   "language": "python",
   "name": "learn-env-bmc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "757px",
    "left": "35px",
    "top": "110px",
    "width": "278.949px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
